{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5dd3548a",
      "metadata": {},
      "source": [
        "# CZ4041 Kaggle Playground S5E9 - BPM Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "523fedc4",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3ca56816",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape: (524164, 11)\n",
            "test shape: (174722, 10)\n",
            "sample_submission shape: (174722, 2)\n",
            "\n",
            "train head:\n",
            "   id  RhythmScore  AudioLoudness  VocalContent  AcousticQuality  InstrumentalScore  LivePerformanceLikelihood  \\\n",
            "0   0     0.603610      -7.636942      0.023500         0.000005           0.000001                   0.051385   \n",
            "1   1     0.639451     -16.267598      0.071520         0.444929           0.349414                   0.170522   \n",
            "2   2     0.514538     -15.953575      0.110715         0.173699           0.453814                   0.029576   \n",
            "3   3     0.734463      -1.357000      0.052965         0.001651           0.159717                   0.086366   \n",
            "4   4     0.532968     -13.056437      0.023500         0.068687           0.000001                   0.331345   \n",
            "\n",
            "   MoodScore  TrackDurationMs    Energy  BeatsPerMinute  \n",
            "0   0.409866      290715.6450  0.826267       147.53020  \n",
            "1   0.651010      164519.5174  0.145400       136.15963  \n",
            "2   0.423865      174495.5667  0.624667        55.31989  \n",
            "3   0.278745      225567.4651  0.487467       147.91212  \n",
            "4   0.477769      213960.6789  0.947333        89.58511  \n",
            "\n",
            "test head:\n",
            "       id  RhythmScore  AudioLoudness  VocalContent  AcousticQuality  InstrumentalScore  LivePerformanceLikelihood  \\\n",
            "0  524164     0.410013     -16.794967      0.023500         0.232910           0.012689                   0.271585   \n",
            "1  524165     0.463071      -1.357000      0.141818         0.057725           0.257942                   0.097624   \n",
            "2  524166     0.686569      -3.368928      0.167851         0.287823           0.210915                   0.325909   \n",
            "3  524167     0.885793      -5.598049      0.118488         0.000005           0.376906                   0.134435   \n",
            "4  524168     0.637391      -7.068160      0.126099         0.539073           0.068950                   0.024300   \n",
            "\n",
            "   MoodScore  TrackDurationMs    Energy  \n",
            "0   0.664321      302901.5498  0.424867  \n",
            "1   0.829552      221995.6643  0.846000  \n",
            "2   0.304978      357724.0127  0.134067  \n",
            "3   0.487740      271790.3989  0.316467  \n",
            "4   0.591248      277728.5383  0.481067  \n",
            "\n",
            "sample_submission head:\n",
            "       id  BeatsPerMinute\n",
            "0  524164         119.035\n",
            "1  524165         119.035\n",
            "2  524166         119.035\n",
            "3  524167         119.035\n",
            "4  524168         119.035\n",
            "\n",
            "train dtypes:\n",
            "id                             int64\n",
            "RhythmScore                  float64\n",
            "AudioLoudness                float64\n",
            "VocalContent                 float64\n",
            "AcousticQuality              float64\n",
            "InstrumentalScore            float64\n",
            "LivePerformanceLikelihood    float64\n",
            "MoodScore                    float64\n",
            "TrackDurationMs              float64\n",
            "Energy                       float64\n",
            "BeatsPerMinute               float64\n",
            "dtype: object\n",
            "\n",
            "test dtypes:\n",
            "id                             int64\n",
            "RhythmScore                  float64\n",
            "AudioLoudness                float64\n",
            "VocalContent                 float64\n",
            "AcousticQuality              float64\n",
            "InstrumentalScore            float64\n",
            "LivePerformanceLikelihood    float64\n",
            "MoodScore                    float64\n",
            "TrackDurationMs              float64\n",
            "Energy                       float64\n",
            "dtype: object\n",
            "\n",
            "sample_submission dtypes:\n",
            "id                  int64\n",
            "BeatsPerMinute    float64\n",
            "dtype: object\n",
            "\n",
            "missing values (train):\n",
            "id                           0\n",
            "RhythmScore                  0\n",
            "AudioLoudness                0\n",
            "VocalContent                 0\n",
            "AcousticQuality              0\n",
            "InstrumentalScore            0\n",
            "LivePerformanceLikelihood    0\n",
            "MoodScore                    0\n",
            "TrackDurationMs              0\n",
            "Energy                       0\n",
            "BeatsPerMinute               0\n",
            "dtype: int64\n",
            "\n",
            "missing values (test):\n",
            "id                           0\n",
            "RhythmScore                  0\n",
            "AudioLoudness                0\n",
            "VocalContent                 0\n",
            "AcousticQuality              0\n",
            "InstrumentalScore            0\n",
            "LivePerformanceLikelihood    0\n",
            "MoodScore                    0\n",
            "TrackDurationMs              0\n",
            "Energy                       0\n",
            "dtype: int64\n",
            "\n",
            "missing values (sample_submission):\n",
            "id                0\n",
            "BeatsPerMinute    0\n",
            "dtype: int64\n",
            "\n",
            "feature columns: ['RhythmScore', 'AudioLoudness', 'VocalContent', 'AcousticQuality', 'InstrumentalScore', 'LivePerformanceLikelihood', 'MoodScore', 'TrackDurationMs', 'Energy']\n",
            "feature count: 9\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ROOT = Path('.')\n",
        "DATA_DIR = ROOT / 'Data'\n",
        "\n",
        "train_path = DATA_DIR / 'train.csv'\n",
        "test_path = DATA_DIR / 'test.csv'\n",
        "sub_path = DATA_DIR / 'sample_submission.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "sub_df = pd.read_csv(sub_path)\n",
        "\n",
        "print('train shape:', train_df.shape)\n",
        "print('test shape:', test_df.shape)\n",
        "print('sample_submission shape:', sub_df.shape)\n",
        "\n",
        "print('\\ntrain head:')\n",
        "print(train_df.head())\n",
        "print('\\ntest head:')\n",
        "print(test_df.head())\n",
        "print('\\nsample_submission head:')\n",
        "print(sub_df.head())\n",
        "\n",
        "print('\\ntrain dtypes:')\n",
        "print(train_df.dtypes)\n",
        "print('\\ntest dtypes:')\n",
        "print(test_df.dtypes)\n",
        "print('\\nsample_submission dtypes:')\n",
        "print(sub_df.dtypes)\n",
        "\n",
        "print('\\nmissing values (train):')\n",
        "print(train_df.isna().sum())\n",
        "print('\\nmissing values (test):')\n",
        "print(test_df.isna().sum())\n",
        "print('\\nmissing values (sample_submission):')\n",
        "print(sub_df.isna().sum())\n",
        "\n",
        "TARGET = 'BeatsPerMinute'\n",
        "ID_COL = 'id'\n",
        "\n",
        "assert TARGET in train_df.columns, \"Expected 'BeatsPerMinute' in train.csv\"\n",
        "assert TARGET not in test_df.columns, \"'BeatsPerMinute' must not be in test.csv\"\n",
        "assert ID_COL in train_df.columns, \"Expected 'id' in train.csv\"\n",
        "assert ID_COL in test_df.columns, \"Expected 'id' in test.csv\"\n",
        "assert list(sub_df.columns) == ['id', 'BeatsPerMinute'], \"sample_submission columns must be ['id','BeatsPerMinute']\"\n",
        "assert len(test_df) == len(sub_df), \"test row count must equal sample_submission row count\"\n",
        "assert np.array_equal(test_df[ID_COL].values, sub_df['id'].values), \"test['id'] must match sample_submission['id'] in the same order\"\n",
        "\n",
        "feature_cols = [c for c in train_df.columns if c not in [ID_COL, TARGET]]\n",
        "assert set(feature_cols) == set([c for c in test_df.columns if c != ID_COL]), \"test feature columns must match train features\"\n",
        "\n",
        "print('\\nfeature columns:', feature_cols)\n",
        "print('feature count:', len(feature_cols))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07cd1627",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31fd892",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ARTIFACTS_DIR = Path('.') / 'artifacts'\n",
        "FIG_DIR = ARTIFACTS_DIR / 'figures'\n",
        "TABLE_DIR = ARTIFACTS_DIR / 'tables'\n",
        "\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Target distribution\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.hist(train_df[TARGET], bins=40, color='#1f77b4', alpha=0.85)\n",
        "plt.title('Target Distribution: BeatsPerMinute')\n",
        "plt.xlabel('BeatsPerMinute')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "fig_path = FIG_DIR / 'target_distribution.png'\n",
        "plt.savefig(fig_path, dpi=150)\n",
        "plt.close()\n",
        "print('Saved:', fig_path.resolve())\n",
        "\n",
        "# Energy histogram\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.hist(train_df['Energy'], bins=40, color='#ff7f0e', alpha=0.85)\n",
        "plt.title('Distribution: Energy')\n",
        "plt.xlabel('Energy')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "fig_path = FIG_DIR / 'energy_distribution.png'\n",
        "plt.savefig(fig_path, dpi=150)\n",
        "plt.close()\n",
        "print('Saved:', fig_path.resolve())\n",
        "\n",
        "# RhythmScore histogram\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.hist(train_df['RhythmScore'], bins=40, color='#2ca02c', alpha=0.85)\n",
        "plt.title('Distribution: RhythmScore')\n",
        "plt.xlabel('RhythmScore')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "fig_path = FIG_DIR / 'rhythmscore_distribution.png'\n",
        "plt.savefig(fig_path, dpi=150)\n",
        "plt.close()\n",
        "print('Saved:', fig_path.resolve())\n",
        "\n",
        "# TrackDurationMs histogram with log1p transform\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.hist(np.log1p(train_df['TrackDurationMs']), bins=40, color='#9467bd', alpha=0.85)\n",
        "plt.title('Distribution: log1p(TrackDurationMs)')\n",
        "plt.xlabel('log1p(TrackDurationMs)')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "fig_path = FIG_DIR / 'trackduration_log1p_distribution.png'\n",
        "plt.savefig(fig_path, dpi=150)\n",
        "plt.close()\n",
        "print('Saved:', fig_path.resolve())\n",
        "\n",
        "# Correlation heatmap (features + target)\n",
        "cols_for_corr = feature_cols + [TARGET]\n",
        "corr = train_df[cols_for_corr].corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(corr.values, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.colorbar(label='Correlation')\n",
        "plt.xticks(range(len(cols_for_corr)), cols_for_corr, rotation=90)\n",
        "plt.yticks(range(len(cols_for_corr)), cols_for_corr)\n",
        "plt.title('Correlation Heatmap (Features + Target)')\n",
        "plt.tight_layout()\n",
        "fig_path = FIG_DIR / 'correlation_heatmap.png'\n",
        "plt.savefig(fig_path, dpi=150)\n",
        "plt.close()\n",
        "print('Saved:', fig_path.resolve())\n",
        "\n",
        "# Train vs test overlay histograms\n",
        "for col, color in [('Energy', '#ff7f0e'), ('RhythmScore', '#2ca02c'), ('TrackDurationMs', '#9467bd')]:\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.hist(train_df[col], bins=40, color=color, alpha=0.6, label='train', density=True)\n",
        "    plt.hist(test_df[col], bins=40, color='gray', alpha=0.4, label='test', density=True)\n",
        "    plt.title(f'Train vs Test: {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    fig_path = FIG_DIR / f'{col.lower()}_train_test_overlay.png'\n",
        "    plt.savefig(fig_path, dpi=150)\n",
        "    plt.close()\n",
        "    print('Saved:', fig_path.resolve())\n",
        "\n",
        "# Tables\n",
        "train_desc = train_df.describe().T\n",
        "train_desc.to_csv(TABLE_DIR / 'train_describe.csv')\n",
        "print('Saved:', (TABLE_DIR / 'train_describe.csv').resolve())\n",
        "\n",
        "test_desc = test_df.describe().T\n",
        "test_desc.to_csv(TABLE_DIR / 'test_describe.csv')\n",
        "print('Saved:', (TABLE_DIR / 'test_describe.csv').resolve())\n",
        "\n",
        "corr_with_target = train_df[feature_cols].corrwith(train_df[TARGET]).sort_values(ascending=False)\n",
        "corr_with_target.to_csv(TABLE_DIR / 'feature_target_correlation.csv', header=['correlation'])\n",
        "print('Saved:', (TABLE_DIR / 'feature_target_correlation.csv').resolve())\n",
        "\n",
        "# Top absolute correlations with target\n",
        "abs_corr = corr_with_target.abs().sort_values(ascending=False)\n",
        "print('\\nTop 3 absolute correlations with target:')\n",
        "print(abs_corr.head(3))\n",
        "\n",
        "# Top KS shifts\n",
        "print('\\nTop 5 most shifted features:')\n",
        "print(ks_df.head(5))\n",
        "\n",
        "# KS shift check\n",
        "ks_rows = []\n",
        "for col in feature_cols:\n",
        "    train_vals = train_df[col].values\n",
        "    test_vals = test_df[col].values\n",
        "    train_sorted = np.sort(train_vals)\n",
        "    test_sorted = np.sort(test_vals)\n",
        "    data_all = np.sort(np.concatenate([train_sorted, test_sorted]))\n",
        "    train_cdf = np.searchsorted(train_sorted, data_all, side='right') / train_sorted.size\n",
        "    test_cdf = np.searchsorted(test_sorted, data_all, side='right') / test_sorted.size\n",
        "    ks_stat = np.max(np.abs(train_cdf - test_cdf))\n",
        "    ks_rows.append({'feature': col, 'ks_stat': ks_stat})\n",
        "\n",
        "ks_df = pd.DataFrame(ks_rows).sort_values('ks_stat', ascending=False)\n",
        "ks_df.to_csv(TABLE_DIR / 'ks_shift.csv', index=False)\n",
        "print('Saved:', (TABLE_DIR / 'ks_shift.csv').resolve())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3788cc9e",
      "metadata": {},
      "source": [
        "## EDA Summary\n",
        "- Strongest absolute correlation with target: MoodScore (|r|=0.0071).\n",
        "- Strongest absolute correlation with target: TrackDurationMs (|r|=0.0066).\n",
        "- Strongest absolute correlation with target: RhythmScore (|r|=0.0054).\n",
        "- Largest train-vs-test shift by KS: TrackDurationMs (KS=0.0023).\n",
        "- Top 5 shifted features: TrackDurationMs, MoodScore, RhythmScore, Energy, InstrumentalScore.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c040b6a",
      "metadata": {},
      "source": [
        "## 3. Baseline Model - LightGBM with 5-Fold Cross Validation\n",
        "\n",
        "### Motivation\n",
        "To establish a strong and reliable reference point, we first train a baseline model using only the raw input features. This baseline represents the best performance achievable without any feature engineering or distribution alignment.\n",
        "\n",
        "LightGBM is chosen because gradient boosting decision trees are well suited for tabular data with nonlinear relationships and feature interactions. They also require minimal preprocessing and are robust to feature scaling.\n",
        "\n",
        "### Method\n",
        "**5-fold cross validation** with shuffling and a fixed random seed to ensure reproducibility.  \n",
        "For each fold:\n",
        "- the model is trained on 4 folds,\n",
        "- validated on the remaining fold,\n",
        "- and early stopping is used to prevent overfitting.\n",
        "\n",
        "Out-of-fold (OOF) predictions are collected for all training samples, and the test predictions are averaged across folds.\n",
        "\n",
        "### Evaluation\n",
        "Performance is measured using **Root Mean Squared Error (RMSE)**.  \n",
        "The mean and standard deviation of RMSE across the 5 folds represent the baseline performance.\n",
        "\n",
        "All subsequent experiments are compared against this baseline to evaluate whether new features or modeling strategies provide real improvements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2201e88f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import lightgbm as lgb\n",
        "\n",
        "RESULTS_DIR = Path('.') / 'artifacts' / 'results'\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def train_cv_lgbm(X, y, X_test, n_splits=5, seed=1, use_h1=False, use_h2=False, use_quantile=True, params=None, num_boost_round=5000, early_stopping_rounds=200, return_best_iteration_mean=False):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(X_test))\n",
        "    fold_scores = []\n",
        "    best_iterations = []\n",
        "\n",
        "    if use_h1:\n",
        "        X = add_h1_features(X)\n",
        "        X_test = add_h1_features(X_test)\n",
        "\n",
        "    numeric_features = list(X.columns)\n",
        "\n",
        "    if params is None:\n",
        "        params = {\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'learning_rate': 0.05,\n",
        "            'num_leaves': 31,\n",
        "            'max_depth': -1,\n",
        "            'feature_fraction': 0.9,\n",
        "            'bagging_fraction': 0.8,\n",
        "            'bagging_freq': 1,\n",
        "            'seed': seed,\n",
        "            'verbosity': -1\n",
        "        }\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "        if use_h2:\n",
        "            n_quantiles = min(1000, len(X_tr))\n",
        "            transformers = [\n",
        "                ('raw', 'passthrough', numeric_features),\n",
        "                ('scaled', StandardScaler(), numeric_features)\n",
        "            ]\n",
        "            if use_quantile:\n",
        "                transformers.append((\n",
        "                    'quantile',\n",
        "                    QuantileTransformer(\n",
        "                        output_distribution='normal',\n",
        "                        n_quantiles=n_quantiles,\n",
        "                        random_state=seed\n",
        "                    ),\n",
        "                    numeric_features\n",
        "                ))\n",
        "            preprocessor = ColumnTransformer(transformers=transformers, remainder='drop')\n",
        "            X_tr_proc = preprocessor.fit_transform(X_tr)\n",
        "            X_va_proc = preprocessor.transform(X_va)\n",
        "            X_test_proc = preprocessor.transform(X_test)\n",
        "        else:\n",
        "            X_tr_proc = X_tr\n",
        "            X_va_proc = X_va\n",
        "            X_test_proc = X_test\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_tr_proc, label=y_tr)\n",
        "        lgb_valid = lgb.Dataset(X_va_proc, label=y_va, reference=lgb_train)\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            num_boost_round=num_boost_round,\n",
        "            valid_sets=[lgb_train, lgb_valid],\n",
        "            valid_names=['train', 'valid'],\n",
        "            callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=False)]\n",
        "        )\n",
        "\n",
        "        best_iterations.append(model.best_iteration)\n",
        "        va_pred = model.predict(X_va_proc, num_iteration=model.best_iteration)\n",
        "        oof_preds[va_idx] = va_pred\n",
        "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
        "        fold_scores.append(rmse)\n",
        "        print(f'Fold {fold} RMSE:', rmse)\n",
        "\n",
        "        test_fold_pred = model.predict(X_test_proc, num_iteration=model.best_iteration)\n",
        "        test_preds += test_fold_pred / n_splits\n",
        "\n",
        "    mean_rmse = float(np.mean(fold_scores))\n",
        "    std_rmse = float(np.std(fold_scores))\n",
        "    if return_best_iteration_mean:\n",
        "        best_iteration_mean = float(np.mean(best_iterations))\n",
        "        return oof_preds, test_preds, fold_scores, mean_rmse, std_rmse, best_iteration_mean\n",
        "    return oof_preds, test_preds, fold_scores, mean_rmse, std_rmse\n",
        "\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "oof_preds, test_preds, fold_scores, mean_rmse, std_rmse = train_cv_lgbm(X, y, X_test, n_splits=5, 1, use_h1=False)\n",
        "\n",
        "baseline_mean_rmse = mean_rmse\n",
        "baseline_std_rmse = std_rmse\n",
        "print('\\nMean RMSE:', mean_rmse)\n",
        "print('Std RMSE:', std_rmse)\n",
        "\n",
        "baseline_folds = pd.DataFrame({'fold': list(range(1, len(fold_scores) + 1)), 'rmse': fold_scores})\n",
        "baseline_folds_path = RESULTS_DIR / 'baseline_folds.csv'\n",
        "baseline_folds.to_csv(baseline_folds_path, index=False)\n",
        "print('Saved:', baseline_folds_path.resolve())\n",
        "\n",
        "baseline_oof = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_preds})\n",
        "baseline_oof_path = RESULTS_DIR / 'baseline_oof.csv'\n",
        "baseline_oof.to_csv(baseline_oof_path, index=False)\n",
        "print('Saved:', baseline_oof_path.resolve())\n",
        "\n",
        "submission_cols = sub_df.columns.tolist()\n",
        "sub = pd.DataFrame({submission_cols[0]: test_df[ID_COL], submission_cols[1]: test_preds})\n",
        "submission_path = RESULTS_DIR / 'submission_baseline.csv'\n",
        "sub.to_csv(submission_path, index=False)\n",
        "print('Saved:', submission_path.resolve())\n",
        "print('\\nSubmission head:')\n",
        "print(sub.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36052ab5",
      "metadata": {},
      "source": [
        "This baseline represents the performance using raw features only. All further improvements are compared against this score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89e6d913",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering - Hypothesis 1 (Interaction Geometry)\n",
        "# Motivation\n",
        "\n",
        "Beats Per Minute (BPM) is not determined by any single audio characteristic in isolation. Instead, tempo emerges from the interaction of multiple perceptual factors, such as energy, rhythm, loudness, and duration.\n",
        "\n",
        "For example, fast songs typically exhibit:\n",
        "\n",
        "- high rhythmic structure,\n",
        "\n",
        "- high perceived energy,\n",
        "\n",
        "- higher loudness,\n",
        "\n",
        "- and shorter durations.\n",
        "\n",
        "However, these relationships are nonlinear and coupled. A track with high energy but low rhythmic structure may not feel fast, while a highly rhythmic track with moderate energy may still feel fast. Tree-based models can learn some of these interactions, but explicitly encoding them can help the model generalize more reliably, especially under slight distribution shifts.\n",
        "\n",
        "Therefore, Hypothesis 1 proposes that explicit interaction and nonlinear features will better represent the latent structure that governs perceived tempo.\n",
        "\n",
        "# Feature Design\n",
        "\n",
        "To capture this geometry, we introduce three groups of features:\n",
        "\n",
        "1) Nonlinear transforms\n",
        "\n",
        "These allow the model to represent curvature in the relationship between features and BPM.\n",
        "\n",
        "- log(TrackDurationMs + 1)\n",
        "\n",
        "- Energy²\n",
        "\n",
        "- RhythmScore²\n",
        "\n",
        "- AudioLoudness²\n",
        "\n",
        "These terms capture diminishing or accelerating effects that a linear feature cannot represent.\n",
        "\n",
        "2) Pairwise interactions\n",
        "\n",
        "These encode how two perceptual dimensions jointly influence tempo.\n",
        "\n",
        "- Energy × RhythmScore\n",
        "\n",
        "- Energy × AudioLoudness\n",
        "\n",
        "- RhythmScore × AudioLoudness\n",
        "\n",
        "These reflect that BPM perception depends on combined intensity and structure, not just independent effects.\n",
        "\n",
        "3) Scale-normalized ratios\n",
        "\n",
        "These control for track length, which strongly influences perceived tempo.\n",
        "\n",
        "- Energy / log(TrackDurationMs + 1)\n",
        "\n",
        "- RhythmScore / log(TrackDurationMs + 1)\n",
        "\n",
        "Short, energetic songs tend to feel faster than long, energetic songs. These ratios normalize energy and rhythm by duration.\n",
        "\n",
        "4) Optional composite cues\n",
        "\n",
        "- Energy × MoodScore\n",
        "\n",
        "- (Energy + RhythmScore) / 2\n",
        "\n",
        "These represent higher-level cues of drive and rhythmic emphasis.\n",
        "\n",
        "#Experimental Goal\n",
        "\n",
        "The objective of H1 is to test whether explicitly encoding nonlinear interactions improves predictive performance over using raw features alone.\n",
        "\n",
        "We compare:\n",
        "\n",
        "| Model    | Features                   | RMSE  |\n",
        "| -------- | -------------------------- | ----- |\n",
        "| Baseline | Raw features               | X     |\n",
        "| H1       | Raw + interaction features | X − Δ |\n",
        "\n",
        "\n",
        "If Δ > 0, it supports the hypothesis that BPM emerges from interaction geometry rather than linear contributions.\n",
        "\n",
        "This approach is:\n",
        "\n",
        "- interpretable (each feature has a perceptual meaning),\n",
        "\n",
        "- experimentally testable (via ablation),\n",
        "\n",
        "- and grounded in how humans perceive tempo.\n",
        "\n",
        "It moves the model from “fitting numbers” to modeling the structure of perception, which strengthens both performance and scientific credibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68f1deb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "USE_H1 = True\n",
        "\n",
        "def add_h1_features(df):\n",
        "    df = df.copy()\n",
        "    eps = 1e-6\n",
        "    log_duration = np.log1p(df['TrackDurationMs'])\n",
        "    df['log1p_TrackDurationMs'] = log_duration\n",
        "    df['Energy_sq'] = df['Energy'] ** 2\n",
        "    df['RhythmScore_sq'] = df['RhythmScore'] ** 2\n",
        "    df['AudioLoudness_sq'] = df['AudioLoudness'] ** 2\n",
        "    df['Energy_x_RhythmScore'] = df['Energy'] * df['RhythmScore']\n",
        "    df['Energy_x_AudioLoudness'] = df['Energy'] * df['AudioLoudness']\n",
        "    df['RhythmScore_x_AudioLoudness'] = df['RhythmScore'] * df['AudioLoudness']\n",
        "    denom = log_duration + eps\n",
        "    df['Energy_div_logDuration'] = df['Energy'] / denom\n",
        "    df['Rhythm_div_logDuration'] = df['RhythmScore'] / denom\n",
        "    df['Energy_x_MoodScore'] = df['Energy'] * df['MoodScore']\n",
        "    df['Energy_Rhythm_mean'] = (df['Energy'] + df['RhythmScore']) / 2.0\n",
        "    return df\n",
        "\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "oof_h1, test_h1, h1_fold_scores, h1_mean_rmse, h1_std_rmse = train_cv_lgbm(\n",
        "    X, y, X_test, n_splits=5, seed=1, use_h1=USE_H1\n",
        ")\n",
        "\n",
        "print('\\nBaseline mean RMSE:', baseline_mean_rmse)\n",
        "print('H1 mean RMSE:', h1_mean_rmse)\n",
        "print('Delta (baseline - H1):', baseline_mean_rmse - h1_mean_rmse)\n",
        "\n",
        "h1_folds = pd.DataFrame({'fold': list(range(1, len(h1_fold_scores) + 1)), 'rmse': h1_fold_scores})\n",
        "h1_folds_path = RESULTS_DIR / 'h1_folds.csv'\n",
        "h1_folds.to_csv(h1_folds_path, index=False)\n",
        "print('Saved:', h1_folds_path.resolve())\n",
        "\n",
        "h1_oof = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_h1})\n",
        "h1_oof_path = RESULTS_DIR / 'h1_oof.csv'\n",
        "h1_oof.to_csv(h1_oof_path, index=False)\n",
        "print('Saved:', h1_oof_path.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0fc52e",
      "metadata": {},
      "source": [
        "### Hypothesis 1 Results Analysis\n",
        "H1 does not improve performance (Δ = −0.0005 RMSE). This does not support the hypothesis that explicitly modeling nonlinear interactions between energy, rhythm, loudness, and duration improves BPM prediction under this setting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d90833",
      "metadata": {},
      "source": [
        "## 5. Feature Engineering - Hypothesis 2 (Distribution Alignment)\n",
        "\n",
        "### Motivation\n",
        "The dataset used in this competition was generated by a deep learning model rather than collected from real audio recordings. As a result, the training and test sets are not guaranteed to follow exactly the same feature distributions, even if they share similar ranges and semantics.\n",
        "\n",
        "In such synthetic settings, models may overfit to the **absolute scale and shape** of the training distribution, which can reduce generalization when the test data is slightly shifted. However, the **relative ordering and rank structure** of features often remains more stable than raw values.\n",
        "\n",
        "Therefore, Hypothesis 2 proposes that **aligning feature distributions** improves generalization and reduces RMSE.\n",
        "\n",
        "### Feature Design\n",
        "For each numeric feature, we construct distribution-aligned representations using:\n",
        "\n",
        "1) **Standardized features (z-score)**  \n",
        "Each feature is centered and scaled to unit variance using statistics computed from the training fold only.\n",
        "\n",
        "2) **Quantile-transformed features**  \n",
        "Each feature is mapped to a Gaussian-like distribution using a quantile transformation fitted on the training fold. This preserves relative ordering while reducing skewness and scale differences.\n",
        "\n",
        "The final H2 representation concatenates:\n",
        "- raw features  \n",
        "- standardized features  \n",
        "- quantile-transformed features  \n",
        "\n",
        "This provides the model with multiple views of the same information: absolute scale, relative scale, and normalized rank structure.\n",
        "\n",
        "All transformations are applied using a cross-validation pipeline to avoid data leakage.\n",
        "\n",
        "### Experimental Goal\n",
        "We evaluate H2 by comparing:\n",
        "\n",
        "| Model    | Features                           | RMSE   |\n",
        "|----------|------------------------------------|--------|\n",
        "| Baseline | Raw features                        | X      |\n",
        "| H2       | Raw + distribution-aligned features | X - Δ  |\n",
        "\n",
        "If Δ > 0, it supports the hypothesis that distribution alignment improves generalization under synthetic train-test shift.\n",
        "\n",
        "### Why this is principled\n",
        "This approach is:\n",
        "- statistically grounded in distribution normalization,\n",
        "- robust to scale and shape differences between datasets,\n",
        "- and well suited to synthetic or model-generated data.\n",
        "\n",
        "H2 focuses not on increasing model capacity, but on improving **how the data is represented**, which can lead to more stable and transferable predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ccabcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "USE_H2 = True\n",
        "USE_QUANTILE = True\n",
        "\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "# Exp2: H2 only\n",
        "oof_h2, test_h2, h2_fold_scores, h2_mean_rmse, h2_std_rmse = train_cv_lgbm(\n",
        "    X, y, X_test, n_splits=5, seed=1, use_h1=False, use_h2=USE_H2, use_quantile=USE_QUANTILE\n",
        ")\n",
        "\n",
        "print('\\nH2 mean RMSE:', h2_mean_rmse)\n",
        "print('H2 std RMSE:', h2_std_rmse)\n",
        "print('Delta vs baseline:', baseline_mean_rmse - h2_mean_rmse)\n",
        "\n",
        "h2_folds = pd.DataFrame({'fold': list(range(1, len(h2_fold_scores) + 1)), 'rmse': h2_fold_scores})\n",
        "h2_folds_path = RESULTS_DIR / 'h2_only_folds.csv'\n",
        "h2_folds.to_csv(h2_folds_path, index=False)\n",
        "print('Saved:', h2_folds_path.resolve())\n",
        "\n",
        "h2_oof = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_h2})\n",
        "h2_oof_path = RESULTS_DIR / 'h2_only_oof.csv'\n",
        "h2_oof.to_csv(h2_oof_path, index=False)\n",
        "print('Saved:', h2_oof_path.resolve())\n",
        "\n",
        "# Exp3: H1 + H2\n",
        "oof_h1_h2, test_h1_h2, h1_h2_fold_scores, h1_h2_mean_rmse, h1_h2_std_rmse = train_cv_lgbm(\n",
        "    X, y, X_test, n_splits=5, seed=1, use_h1=True, use_h2=USE_H2, use_quantile=USE_QUANTILE\n",
        ")\n",
        "\n",
        "print('\\nH1+H2 mean RMSE:', h1_h2_mean_rmse)\n",
        "print('H1+H2 std RMSE:', h1_h2_std_rmse)\n",
        "print('Delta vs baseline:', baseline_mean_rmse - h1_h2_mean_rmse)\n",
        "\n",
        "h1_h2_folds = pd.DataFrame({'fold': list(range(1, len(h1_h2_fold_scores) + 1)), 'rmse': h1_h2_fold_scores})\n",
        "h1_h2_folds_path = RESULTS_DIR / 'h1_h2_folds.csv'\n",
        "h1_h2_folds.to_csv(h1_h2_folds_path, index=False)\n",
        "print('Saved:', h1_h2_folds_path.resolve())\n",
        "\n",
        "h1_h2_oof = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_h1_h2})\n",
        "h1_h2_oof_path = RESULTS_DIR / 'h1_h2_oof.csv'\n",
        "h1_h2_oof.to_csv(h1_h2_oof_path, index=False)\n",
        "print('Saved:', h1_h2_oof_path.resolve())\n",
        "\n",
        "experiments = pd.DataFrame([\n",
        "    {\n",
        "        'experiment_name': 'baseline',\n",
        "        'use_h1': False,\n",
        "        'use_h2': False,\n",
        "        'use_quantile': False,\n",
        "        'mean_rmse': baseline_mean_rmse,\n",
        "        'std_rmse': baseline_std_rmse\n",
        "    },\n",
        "    {\n",
        "        'experiment_name': 'h1',\n",
        "        'use_h1': True,\n",
        "        'use_h2': False,\n",
        "        'use_quantile': False,\n",
        "        'mean_rmse': h1_mean_rmse,\n",
        "        'std_rmse': h1_std_rmse\n",
        "    },\n",
        "    {\n",
        "        'experiment_name': 'h2_only',\n",
        "        'use_h1': False,\n",
        "        'use_h2': True,\n",
        "        'use_quantile': USE_QUANTILE,\n",
        "        'mean_rmse': h2_mean_rmse,\n",
        "        'std_rmse': h2_std_rmse\n",
        "    },\n",
        "    {\n",
        "        'experiment_name': 'h1_h2',\n",
        "        'use_h1': True,\n",
        "        'use_h2': True,\n",
        "        'use_quantile': USE_QUANTILE,\n",
        "        'mean_rmse': h1_h2_mean_rmse,\n",
        "        'std_rmse': h1_h2_std_rmse\n",
        "    }\n",
        "])\n",
        "\n",
        "experiments_path = RESULTS_DIR / 'experiments.csv'\n",
        "experiments.to_csv(experiments_path, index=False)\n",
        "print('Saved:', experiments_path.resolve())\n",
        "\n",
        "h2_delta = baseline_mean_rmse - h2_mean_rmse\n",
        "h1_h2_delta = baseline_mean_rmse - h1_h2_mean_rmse\n",
        "print('\\nInterpretation (H2):')\n",
        "print('H2 improves by' if h2_delta > 0 else 'H2 does not improve, delta', h2_delta)\n",
        "print('H1+H2 improves by' if h1_h2_delta > 0 else 'H1+H2 does not improve, delta', h1_h2_delta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a0a322f",
      "metadata": {},
      "source": [
        "## 6. Hyperparameter Tuning (LightGBM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebdc0b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def random_search_lgbm(X, y, n_trials=25, seed=1):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    results = []\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "    def sample_params():\n",
        "        lr = float(np.exp(rng.uniform(np.log(0.01), np.log(0.2))))\n",
        "        num_leaves = int(rng.integers(16, 513))\n",
        "        max_depth = int(rng.integers(3, 13))\n",
        "        if rng.random() < 0.2:\n",
        "            max_depth = -1\n",
        "        min_child_samples = int(rng.integers(5, 201))\n",
        "        subsample = float(rng.uniform(0.6, 1.0))\n",
        "        colsample = float(rng.uniform(0.6, 1.0))\n",
        "        reg_alpha = float(np.exp(rng.uniform(np.log(1e-8), np.log(10.0))))\n",
        "        reg_lambda = float(np.exp(rng.uniform(np.log(1e-8), np.log(10.0))))\n",
        "        min_split_gain = float(rng.uniform(0.0, 0.5))\n",
        "        return {\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'learning_rate': lr,\n",
        "            'num_leaves': num_leaves,\n",
        "            'max_depth': max_depth,\n",
        "            'min_child_samples': min_child_samples,\n",
        "            'subsample': subsample,\n",
        "            'colsample_bytree': colsample,\n",
        "            'reg_alpha': reg_alpha,\n",
        "            'reg_lambda': reg_lambda,\n",
        "            'min_split_gain': min_split_gain,\n",
        "            'seed': seed,\n",
        "            'verbosity': -1\n",
        "        }\n",
        "\n",
        "    for trial in range(1, n_trials + 1):\n",
        "        params = sample_params()\n",
        "        start = time.time()\n",
        "        fold_scores = []\n",
        "        best_iters = []\n",
        "        for tr_idx, va_idx in kf.split(X):\n",
        "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "            y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "            lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
        "            lgb_valid = lgb.Dataset(X_va, label=y_va, reference=lgb_train)\n",
        "\n",
        "            model = lgb.train(\n",
        "                params,\n",
        "                lgb_train,\n",
        "                num_boost_round=10000,\n",
        "                valid_sets=[lgb_train, lgb_valid],\n",
        "                valid_names=['train', 'valid'],\n",
        "                callbacks=[lgb.early_stopping(200, verbose=False)]\n",
        "            )\n",
        "\n",
        "            va_pred = model.predict(X_va, num_iteration=model.best_iteration)\n",
        "            rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
        "            fold_scores.append(rmse)\n",
        "            best_iters.append(model.best_iteration)\n",
        "\n",
        "        mean_rmse = float(np.mean(fold_scores))\n",
        "        std_rmse = float(np.std(fold_scores))\n",
        "        runtime_sec = float(time.time() - start)\n",
        "        best_iter_mean = float(np.mean(best_iters))\n",
        "\n",
        "        results.append({\n",
        "            'trial_id': trial,\n",
        "            'params': params,\n",
        "            'mean_rmse': mean_rmse,\n",
        "            'std_rmse': std_rmse,\n",
        "            'best_iteration_mean': best_iter_mean,\n",
        "            'runtime_sec': runtime_sec\n",
        "        })\n",
        "        print(f'Trial {trial}: mean RMSE={mean_rmse:.6f}, std RMSE={std_rmse:.6f}')\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values('mean_rmse', ascending=True)\n",
        "    best_params = results_df.iloc[0]['params']\n",
        "    return results_df, best_params\n",
        "\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "\n",
        "tuning_results, best_params = random_search_lgbm(X, y, n_trials=25, seed=1)\n",
        "tuning_path = RESULTS_DIR / 'lgbm_tuning.csv'\n",
        "tuning_results.to_csv(tuning_path, index=False)\n",
        "print('Saved:', tuning_path.resolve())\n",
        "print('\\nTop 5 trials:')\n",
        "print(tuning_results.head(5))\n",
        "print('\\nBest params:')\n",
        "print(best_params)\n",
        "\n",
        "oof_best, test_best, best_fold_scores, best_mean_rmse, best_std_rmse, best_iter_mean = train_cv_lgbm(\n",
        "    X, y, test_df[feature_cols], n_splits=5, seed=1, use_h1=False, use_h2=False, use_quantile=False,\n",
        "    params=best_params, num_boost_round=10000, early_stopping_rounds=200, return_best_iteration_mean=True\n",
        ")\n",
        "\n",
        "best_folds = pd.DataFrame({'fold': list(range(1, len(best_fold_scores) + 1)), 'rmse': best_fold_scores})\n",
        "best_folds_path = RESULTS_DIR / 'lgbm_best_folds.csv'\n",
        "best_folds.to_csv(best_folds_path, index=False)\n",
        "print('Saved:', best_folds_path.resolve())\n",
        "\n",
        "best_oof = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_best})\n",
        "best_oof_path = RESULTS_DIR / 'lgbm_best_oof.csv'\n",
        "best_oof.to_csv(best_oof_path, index=False)\n",
        "print('Saved:', best_oof_path.resolve())\n",
        "\n",
        "submission_cols = sub_df.columns.tolist()\n",
        "sub_best = pd.DataFrame({submission_cols[0]: test_df[ID_COL], submission_cols[1]: test_best})\n",
        "sub_best_path = RESULTS_DIR / 'submission_lgbm_best.csv'\n",
        "sub_best.to_csv(sub_best_path, index=False)\n",
        "print('Saved:', sub_best_path.resolve())\n",
        "print('\\nBest model RMSE:', best_mean_rmse)\n",
        "print('Best model std RMSE:', best_std_rmse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03d9144",
      "metadata": {},
      "source": [
        "## 7. Ensembling - Blend / Stacking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0b5952",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "try:\n",
        "    from catboost import CatBoostRegressor\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    print('Missing CatBoost or LightGBM. Install with: pip install catboost lightgbm')\n",
        "    raise SystemExit(0)\n",
        "\n",
        "TARGET = 'BeatsPerMinute'\n",
        "ID_COL = 'id'\n",
        "SEED = 1\n",
        "N_SPLITS = 5\n",
        "\n",
        "DATA_DIR = Path('./Data')\n",
        "RESULTS_DIR = Path('./artifacts/results')\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if 'train_df' not in globals() or 'test_df' not in globals() or 'sub_df' not in globals():\n",
        "    train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
        "    test_df = pd.read_csv(DATA_DIR / 'test.csv')\n",
        "    sub_df = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
        "\n",
        "feature_cols = [c for c in train_df.columns if c not in [ID_COL, TARGET]]\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "np.random.seed(SEED)\n",
        "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "# LightGBM CV\n",
        "lgb_oof = np.zeros(len(X))\n",
        "lgb_test = np.zeros(len(X_test))\n",
        "lgb_fold_scores = []\n",
        "\n",
        "params_lgb = dict(\n",
        "    n_estimators=20000,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=256,\n",
        "    max_depth=-1,\n",
        "    min_child_samples=40,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.0,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    model = lgb.LGBMRegressor(**params_lgb)\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_va, y_va)],\n",
        "        eval_metric='rmse',\n",
        "        callbacks=[lgb.early_stopping(300, verbose=False)]\n",
        "    )\n",
        "\n",
        "    best_iter = getattr(model, 'best_iteration_', None)\n",
        "    if best_iter is None:\n",
        "        va_pred = model.predict(X_va)\n",
        "        test_fold = model.predict(X_test)\n",
        "    else:\n",
        "        va_pred = model.predict(X_va, num_iteration=best_iter)\n",
        "        test_fold = model.predict(X_test, num_iteration=best_iter)\n",
        "\n",
        "    rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
        "    lgb_fold_scores.append(rmse)\n",
        "    lgb_oof[va_idx] = va_pred\n",
        "    lgb_test += test_fold / N_SPLITS\n",
        "    print(f'LGB Fold {fold} RMSE:', rmse)\n",
        "\n",
        "lgb_mean = float(np.mean(lgb_fold_scores))\n",
        "lgb_std = float(np.std(lgb_fold_scores))\n",
        "print('LGB Mean RMSE:', lgb_mean)\n",
        "print('LGB Std RMSE:', lgb_std)\n",
        "\n",
        "lgb_oof_df = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': lgb_oof})\n",
        "lgb_oof_path = RESULTS_DIR / 'lgb_oof_cbblend.csv'\n",
        "lgb_oof_df.to_csv(lgb_oof_path, index=False)\n",
        "print('Saved:', lgb_oof_path.resolve())\n",
        "\n",
        "lgb_test_df = pd.DataFrame({ID_COL: test_df[ID_COL], 'pred': lgb_test})\n",
        "lgb_test_path = RESULTS_DIR / 'lgb_test_cbblend.csv'\n",
        "lgb_test_df.to_csv(lgb_test_path, index=False)\n",
        "print('Saved:', lgb_test_path.resolve())\n",
        "\n",
        "lgb_folds_df = pd.DataFrame({'fold': list(range(1, len(lgb_fold_scores) + 1)), 'rmse': lgb_fold_scores})\n",
        "lgb_folds_path = RESULTS_DIR / 'lgb_folds_cbblend.csv'\n",
        "lgb_folds_df.to_csv(lgb_folds_path, index=False)\n",
        "print('Saved:', lgb_folds_path.resolve())\n",
        "\n",
        "# CatBoost CV\n",
        "cb_oof = np.zeros(len(X))\n",
        "cb_test = np.zeros(len(X_test))\n",
        "cb_fold_scores = []\n",
        "\n",
        "params_cb = dict(\n",
        "    loss_function='RMSE',\n",
        "    iterations=20000,\n",
        "    learning_rate=0.03,\n",
        "    depth=10,\n",
        "    l2_leaf_reg=5.0,\n",
        "    random_seed=SEED,\n",
        "    eval_metric='RMSE',\n",
        "    od_type='Iter',\n",
        "    od_wait=300,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    model = CatBoostRegressor(**params_cb)\n",
        "    model.fit(X_tr, y_tr, eval_set=(X_va, y_va), use_best_model=True)\n",
        "\n",
        "    va_pred = model.predict(X_va)\n",
        "    test_fold = model.predict(X_test)\n",
        "\n",
        "    rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
        "    cb_fold_scores.append(rmse)\n",
        "    cb_oof[va_idx] = va_pred\n",
        "    cb_test += test_fold / N_SPLITS\n",
        "    print(f'CB Fold {fold} RMSE:', rmse)\n",
        "\n",
        "cb_mean = float(np.mean(cb_fold_scores))\n",
        "cb_std = float(np.std(cb_fold_scores))\n",
        "print('CB Mean RMSE:', cb_mean)\n",
        "print('CB Std RMSE:', cb_std)\n",
        "\n",
        "cb_oof_df = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': cb_oof})\n",
        "cb_oof_path = RESULTS_DIR / 'cb_oof.csv'\n",
        "cb_oof_df.to_csv(cb_oof_path, index=False)\n",
        "print('Saved:', cb_oof_path.resolve())\n",
        "\n",
        "cb_test_df = pd.DataFrame({ID_COL: test_df[ID_COL], 'pred': cb_test})\n",
        "cb_test_path = RESULTS_DIR / 'cb_test_preds.csv'\n",
        "cb_test_df.to_csv(cb_test_path, index=False)\n",
        "print('Saved:', cb_test_path.resolve())\n",
        "\n",
        "cb_folds_df = pd.DataFrame({'fold': list(range(1, len(cb_fold_scores) + 1)), 'rmse': cb_fold_scores})\n",
        "cb_folds_path = RESULTS_DIR / 'cb_folds.csv'\n",
        "cb_folds_df.to_csv(cb_folds_path, index=False)\n",
        "print('Saved:', cb_folds_path.resolve())\n",
        "\n",
        "# OOF blending\n",
        "weights = np.linspace(0.0, 1.0, 51)\n",
        "blend_rows = []\n",
        "for w in weights:\n",
        "    blended_oof = w * lgb_oof + (1.0 - w) * cb_oof\n",
        "    rmse = float(np.sqrt(mean_squared_error(y, blended_oof)))\n",
        "    blend_rows.append({'weight_lgbm': w, 'rmse': rmse})\n",
        "\n",
        "blend_df = pd.DataFrame(blend_rows).sort_values('rmse', ascending=True)\n",
        "blend_path = RESULTS_DIR / 'blend_weight_search_lgb_cb.csv'\n",
        "blend_df.to_csv(blend_path, index=False)\n",
        "print('Saved:', blend_path.resolve())\n",
        "\n",
        "best_w = float(blend_df.iloc[0]['weight_lgbm'])\n",
        "best_blend_rmse = float(blend_df.iloc[0]['rmse'])\n",
        "print('Best blend weight (LGBM):', best_w)\n",
        "print('Best blended RMSE:', best_blend_rmse)\n",
        "\n",
        "blend_test = best_w * lgb_test + (1.0 - best_w) * cb_test\n",
        "submission = sub_df.copy()\n",
        "submission['BeatsPerMinute'] = blend_test\n",
        "sub_blend_path = RESULTS_DIR / 'submission_blend_lgb_cb.csv'\n",
        "submission.to_csv(sub_blend_path, index=False)\n",
        "print('Saved:', sub_blend_path.resolve())\n",
        "print('\\nSubmission head:')\n",
        "print(submission.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08d44608",
      "metadata": {},
      "source": [
        "## 8. Seed Averaged LightGBM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8875840",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "TARGET = 'BeatsPerMinute'\n",
        "ID_COL = 'id'\n",
        "SEED_LIST = [1]\n",
        "N_SPLITS = 5\n",
        "\n",
        "DATA_DIR = Path('./Data')\n",
        "RESULTS_DIR = Path('./artifacts/results')\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if 'train_df' not in globals() or 'test_df' not in globals() or 'sub_df' not in globals():\n",
        "    train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
        "    test_df = pd.read_csv(DATA_DIR / 'test.csv')\n",
        "    sub_df = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
        "\n",
        "feature_cols = [c for c in train_df.columns if c not in [ID_COL, TARGET]]\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "tuning_path = RESULTS_DIR / 'lgbm_tuning.csv'\n",
        "params = None\n",
        "if tuning_path.exists():\n",
        "    tuning_df = pd.read_csv(tuning_path)\n",
        "    if 'params' in tuning_df.columns:\n",
        "        best_params_raw = tuning_df.loc[tuning_df['mean_rmse'].idxmin(), 'params']\n",
        "        try:\n",
        "            best_params = eval(best_params_raw)\n",
        "            if isinstance(best_params, dict):\n",
        "                params = best_params\n",
        "        except Exception:\n",
        "            params = None\n",
        "\n",
        "if params is None:\n",
        "    params = dict(\n",
        "        objective='regression',\n",
        "        metric='rmse',\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=256,\n",
        "        max_depth=-1,\n",
        "        min_child_samples=40,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.0,\n",
        "        reg_lambda=1.0\n",
        "    )\n",
        "\n",
        "params.pop('random_state', None)\n",
        "params.pop('seed', None)\n",
        "\n",
        "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "oof_list = []\n",
        "test_list = []\n",
        "seed_scores = []\n",
        "\n",
        "for seed in SEED_LIST:\n",
        "    oof_seed = np.zeros(len(X))\n",
        "    test_seed = np.zeros(len(X_test))\n",
        "\n",
        "    for tr_idx, va_idx in kf.split(X):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "        model = lgb.LGBMRegressor(\n",
        "            **params,\n",
        "            n_estimators=20000,\n",
        "            random_state=seed,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        model.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_va, y_va)],\n",
        "            eval_metric='rmse',\n",
        "            callbacks=[lgb.early_stopping(300, verbose=False)]\n",
        "        )\n",
        "\n",
        "        best_iter = getattr(model, 'best_iteration_', None)\n",
        "        if best_iter is None:\n",
        "            va_pred = model.predict(X_va)\n",
        "            test_fold = model.predict(X_test)\n",
        "        else:\n",
        "            va_pred = model.predict(X_va, num_iteration=best_iter)\n",
        "            test_fold = model.predict(X_test, num_iteration=best_iter)\n",
        "\n",
        "        oof_seed[va_idx] = va_pred\n",
        "        test_seed += test_fold / N_SPLITS\n",
        "\n",
        "    rmse_seed = float(np.sqrt(mean_squared_error(y, oof_seed)))\n",
        "    oof_list.append(oof_seed)\n",
        "    test_list.append(test_seed)\n",
        "    seed_scores.append({'seed': seed, 'rmse': rmse_seed})\n",
        "    print(f'Seed {seed} RMSE:', rmse_seed)\n",
        "\n",
        "oof_avg = np.mean(np.vstack(oof_list), axis=0)\n",
        "test_avg = np.mean(np.vstack(test_list), axis=0)\n",
        "avg_rmse = float(np.sqrt(mean_squared_error(y, oof_avg)))\n",
        "print('Averaged OOF RMSE:', avg_rmse)\n",
        "\n",
        "oof_df = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_avg})\n",
        "oof_path = RESULTS_DIR / 'lgbm_tuned_seedavg_oof.csv'\n",
        "oof_df.to_csv(oof_path, index=False)\n",
        "print('Saved:', oof_path.resolve())\n",
        "\n",
        "submission = sub_df.copy()\n",
        "submission['BeatsPerMinute'] = test_avg\n",
        "submission_path = RESULTS_DIR / 'submission_lgbm_tuned_seedavg.csv'\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print('Saved:', submission_path.resolve())\n",
        "print('\\nSubmission head:')\n",
        "print(submission.head())\n",
        "\n",
        "seed_scores_df = pd.DataFrame(seed_scores)\n",
        "seed_scores_path = RESULTS_DIR / 'lgbm_tuned_seedavg_seed_scores.csv'\n",
        "seed_scores_df.to_csv(seed_scores_path, index=False)\n",
        "print('Saved:', seed_scores_path.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3d9fd06",
      "metadata": {},
      "source": [
        "## 8.5 Improved Seed Averaging (LightGBM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a28c24d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "TARGET = 'BeatsPerMinute'\n",
        "ID_COL = 'id'\n",
        "SEED_LIST = [1,2,3]\n",
        "N_SPLITS = 5\n",
        "\n",
        "DATA_DIR = Path('./Data')\n",
        "RESULTS_DIR = Path('./artifacts/results')\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if 'train_df' not in globals() or 'test_df' not in globals() or 'sub_df' not in globals():\n",
        "    train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
        "    test_df = pd.read_csv(DATA_DIR / 'test.csv')\n",
        "    sub_df = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
        "\n",
        "feature_cols = [c for c in train_df.columns if c not in [ID_COL, TARGET]]\n",
        "X = train_df[feature_cols]\n",
        "y = train_df[TARGET]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "tuning_path = RESULTS_DIR / 'lgbm_tuning.csv'\n",
        "best_params = None\n",
        "if tuning_path.exists():\n",
        "    tuning_df = pd.read_csv(tuning_path)\n",
        "    if 'params' in tuning_df.columns:\n",
        "        best_params_raw = tuning_df.loc[tuning_df['mean_rmse'].idxmin(), 'params']\n",
        "        try:\n",
        "            parsed = eval(best_params_raw)\n",
        "            if isinstance(parsed, dict):\n",
        "                best_params = parsed\n",
        "        except Exception:\n",
        "            best_params = None\n",
        "\n",
        "if best_params is None:\n",
        "    best_params = dict(\n",
        "        objective='regression',\n",
        "        metric='rmse',\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=256,\n",
        "        max_depth=-1,\n",
        "        min_child_samples=40,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.0,\n",
        "        reg_lambda=1.0\n",
        "    )\n",
        "\n",
        "best_params.pop('random_state', None)\n",
        "best_params.pop('seed', None)\n",
        "\n",
        "# Two param variants to average (stability + small diversity)\n",
        "param_grid = [\n",
        "    dict(best_params),\n",
        "    dict(best_params, learning_rate=0.04, num_leaves=192, min_child_samples=30),\n",
        "    dict(best_params, learning_rate=0.02, num_leaves=320, min_child_samples=50)\n",
        "]\n",
        "\n",
        "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "oof_runs = []\n",
        "test_runs = []\n",
        "run_scores = []\n",
        "\n",
        "for p_idx, params in enumerate(param_grid, start=1):\n",
        "    for seed in SEED_LIST:\n",
        "        oof = np.zeros(len(X))\n",
        "        test_pred = np.zeros(len(X_test))\n",
        "\n",
        "        for tr_idx, va_idx in kf.split(X):\n",
        "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "            y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "            model = lgb.LGBMRegressor(\n",
        "                **params,\n",
        "                n_estimators=30000,\n",
        "                random_state=seed,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            model.fit(\n",
        "                X_tr, y_tr,\n",
        "                eval_set=[(X_va, y_va)],\n",
        "                eval_metric='rmse',\n",
        "                callbacks=[lgb.early_stopping(500, verbose=False)]\n",
        "            )\n",
        "\n",
        "            best_iter = getattr(model, 'best_iteration_', None)\n",
        "            if best_iter is None:\n",
        "                va_pred = model.predict(X_va)\n",
        "                test_fold = model.predict(X_test)\n",
        "            else:\n",
        "                va_pred = model.predict(X_va, num_iteration=best_iter)\n",
        "                test_fold = model.predict(X_test, num_iteration=best_iter)\n",
        "\n",
        "            oof[va_idx] = va_pred\n",
        "            test_pred += test_fold / N_SPLITS\n",
        "\n",
        "        rmse = float(np.sqrt(mean_squared_error(y, oof)))\n",
        "        oof_runs.append(oof)\n",
        "        test_runs.append(test_pred)\n",
        "        run_scores.append({'param_set': p_idx, 'seed': seed, 'rmse': rmse})\n",
        "        print(f'ParamSet {p_idx} Seed {seed} RMSE:', rmse)\n",
        "\n",
        "oof_avg = np.mean(np.vstack(oof_runs), axis=0)\n",
        "test_avg = np.mean(np.vstack(test_runs), axis=0)\n",
        "avg_rmse = float(np.sqrt(mean_squared_error(y, oof_avg)))\n",
        "print('Averaged OOF RMSE:', avg_rmse)\n",
        "\n",
        "oof_df = pd.DataFrame({ID_COL: train_df[ID_COL], 'oof_pred': oof_avg})\n",
        "oof_path = RESULTS_DIR / 'lgbm_tuned_seedavg_v3_oof.csv'\n",
        "oof_df.to_csv(oof_path, index=False)\n",
        "print('Saved:', oof_path.resolve())\n",
        "\n",
        "run_scores_df = pd.DataFrame(run_scores)\n",
        "run_scores_path = RESULTS_DIR / 'lgbm_tuned_seedavg_v3_run_scores.csv'\n",
        "run_scores_df.to_csv(run_scores_path, index=False)\n",
        "print('Saved:', run_scores_path.resolve())\n",
        "\n",
        "submission = sub_df.copy()\n",
        "submission['BeatsPerMinute'] = test_avg\n",
        "submission_path = RESULTS_DIR / 'submission_lgbm_tuned_seedavg_v3.csv'\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print('Saved:', submission_path.resolve())\n",
        "print('\\nSubmission head:')\n",
        "print(submission.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56859ead",
      "metadata": {},
      "source": [
        "## 9. True Stacking (Meta-Model on OOF Predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bdbf64",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "TARGET = 'BeatsPerMinute'\n",
        "ID_COL = 'id'\n",
        "SEED = 1\n",
        "\n",
        "DATA_DIR = Path('./Data')\n",
        "RESULTS_DIR = Path('./artifacts/results')\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if 'train_df' not in globals() or 'test_df' not in globals() or 'sub_df' not in globals():\n",
        "    train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
        "    test_df = pd.read_csv(DATA_DIR / 'test.csv')\n",
        "    sub_df = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
        "\n",
        "y = train_df[TARGET].values\n",
        "\n",
        "def _pick_pred_col(df, candidates):\n",
        "    for col in candidates:\n",
        "        if col in df.columns:\n",
        "            return col\n",
        "    num_cols = [c for c in df.columns if c != ID_COL]\n",
        "    if len(num_cols) == 1:\n",
        "        return num_cols[0]\n",
        "    return None\n",
        "\n",
        "def load_pred_pair(oof_path, test_path, oof_col_guess=None, test_col_guess=None):\n",
        "    if not oof_path.exists() or not test_path.exists():\n",
        "        return None, None\n",
        "    oof_df = pd.read_csv(oof_path)\n",
        "    test_df_local = pd.read_csv(test_path)\n",
        "\n",
        "    oof_col = _pick_pred_col(oof_df, [oof_col_guess, 'oof_pred', 'BeatsPerMinute', 'pred'])\n",
        "    test_col = _pick_pred_col(test_df_local, [test_col_guess, 'BeatsPerMinute', 'pred'])\n",
        "    if oof_col is None or test_col is None:\n",
        "        return None, None\n",
        "\n",
        "    oof_merged = train_df[[ID_COL]].merge(oof_df[[ID_COL, oof_col]], on=ID_COL, how='left')\n",
        "    test_merged = test_df[[ID_COL]].merge(test_df_local[[ID_COL, test_col]], on=ID_COL, how='left')\n",
        "    if oof_merged[oof_col].isna().any() or test_merged[test_col].isna().any():\n",
        "        return None, None\n",
        "\n",
        "    return oof_merged[oof_col].values, test_merged[test_col].values\n",
        "\n",
        "models = []\n",
        "oof_list = []\n",
        "test_list = []\n",
        "\n",
        "# LightGBM seed-avg (preferred)\n",
        "oof, test = load_pred_pair(\n",
        "    RESULTS_DIR / 'lgbm_tuned_seedavg_oof.csv',\n",
        "    RESULTS_DIR / 'submission_lgbm_tuned_seedavg.csv',\n",
        "    oof_col_guess='oof_pred',\n",
        "    test_col_guess='BeatsPerMinute'\n",
        ")\n",
        "if oof is None or test is None:\n",
        "    oof, test = load_pred_pair(\n",
        "        RESULTS_DIR / 'lgbm_best_oof.csv',\n",
        "        RESULTS_DIR / 'submission_lgbm_best.csv',\n",
        "        oof_col_guess='oof_pred',\n",
        "        test_col_guess='BeatsPerMinute'\n",
        "    )\n",
        "    if oof is None or test is None:\n",
        "        oof, test = load_pred_pair(\n",
        "            RESULTS_DIR / 'baseline_oof.csv',\n",
        "            RESULTS_DIR / 'submission_baseline.csv',\n",
        "            oof_col_guess='oof_pred',\n",
        "            test_col_guess='BeatsPerMinute'\n",
        "        )\n",
        "if oof is not None and test is not None:\n",
        "    models.append('lgbm')\n",
        "    oof_list.append(oof)\n",
        "    test_list.append(test)\n",
        "\n",
        "# CatBoost\n",
        "oof, test = load_pred_pair(\n",
        "    RESULTS_DIR / 'cb_oof.csv',\n",
        "    RESULTS_DIR / 'cb_test_preds.csv',\n",
        "    oof_col_guess='oof_pred',\n",
        "    test_col_guess='pred'\n",
        ")\n",
        "if oof is not None and test is not None:\n",
        "    models.append('catboost')\n",
        "    oof_list.append(oof)\n",
        "    test_list.append(test)\n",
        "\n",
        "# XGBoost\n",
        "oof, test = load_pred_pair(\n",
        "    RESULTS_DIR / 'xgb_oof.csv',\n",
        "    RESULTS_DIR / 'xgb_test_preds.csv',\n",
        "    oof_col_guess='oof_pred',\n",
        "    test_col_guess='pred'\n",
        ")\n",
        "if oof is not None and test is not None:\n",
        "    models.append('xgboost')\n",
        "    oof_list.append(oof)\n",
        "    test_list.append(test)\n",
        "\n",
        "if len(models) < 2:\n",
        "    print('Need at least 2 base models for stacking. Check saved OOF/test predictions.')\n",
        "    raise SystemExit(0)\n",
        "\n",
        "X_meta_train = np.column_stack(oof_list)\n",
        "X_meta_test = np.column_stack(test_list)\n",
        "print('Base models used:', models)\n",
        "print('X_meta_train shape:', X_meta_train.shape)\n",
        "\n",
        "grid = np.linspace(0.0, 1.0, 51)\n",
        "weights = []\n",
        "if len(models) == 2:\n",
        "    for w in grid:\n",
        "        weights.append([w, 1.0 - w])\n",
        "elif len(models) == 3:\n",
        "    for w1 in grid:\n",
        "        for w2 in grid:\n",
        "            w3 = 1.0 - w1 - w2\n",
        "            if w3 < 0:\n",
        "                continue\n",
        "            weights.append([w1, w2, w3])\n",
        "else:\n",
        "    print('This constrained search supports 2 or 3 models only.')\n",
        "    raise SystemExit(0)\n",
        "\n",
        "weights = np.array(weights)\n",
        "blend_rows = []\n",
        "for w in weights:\n",
        "    blended_oof = X_meta_train @ w\n",
        "    rmse = float(np.sqrt(mean_squared_error(y, blended_oof)))\n",
        "    row = {f'weight_{name}': float(w[i]) for i, name in enumerate(models)}\n",
        "    row['rmse'] = rmse\n",
        "    blend_rows.append(row)\n",
        "\n",
        "blend_df = pd.DataFrame(blend_rows).sort_values('rmse', ascending=True)\n",
        "blend_path = RESULTS_DIR / 'stack_constrained_weights.csv'\n",
        "blend_df.to_csv(blend_path, index=False)\n",
        "print('Saved:', blend_path.resolve())\n",
        "\n",
        "best_row = blend_df.iloc[0]\n",
        "best_rmse = float(best_row['rmse'])\n",
        "best_weights = np.array([best_row[f'weight_{name}'] for name in models], dtype=float)\n",
        "\n",
        "stacked_test = X_meta_test @ best_weights\n",
        "\n",
        "coeffs_df = pd.DataFrame({'model': models, 'coef': best_weights})\n",
        "coeffs_path = RESULTS_DIR / 'stack_constrained_coeffs.csv'\n",
        "coeffs_df.to_csv(coeffs_path, index=False)\n",
        "print('Saved:', coeffs_path.resolve())\n",
        "\n",
        "submission = sub_df.copy()\n",
        "submission['BeatsPerMinute'] = stacked_test\n",
        "submission_path = RESULTS_DIR / 'submission_stacking_constrained.csv'\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print('Saved:', submission_path.resolve())\n",
        "print('\\nSubmission head:')\n",
        "print(submission.head())\n",
        "\n",
        "print('\\nStacking summary:')\n",
        "print('Models:', models)\n",
        "print('Best constrained RMSE:', best_rmse)\n",
        "print('Weights:', best_weights.tolist())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_cz4041 (3.12.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
